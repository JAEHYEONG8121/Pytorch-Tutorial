{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAEHYEONG8121/Pytorch-Tutorial/blob/main/Transfer_Learning_%26_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y_9PxnJbBTx"
      },
      "source": [
        "## Transfer Learning & Fine Tuning\n",
        "\n",
        "> Transfer Learning is a machine learning technique where a pre-trained model, originally trained on a large dataset for a specific tast, is adapted to a different but related task.\n",
        "***\n",
        "\n",
        "**Key Concepts of Transfer Learning**\n",
        "\n",
        "1. Pre-trained Model\n",
        "\n",
        "2. Source Task and Target Tast\n",
        "  - Source Task : The original task on which the model was trained\n",
        "  - Target Tast : The new task to which model is being adapted\n",
        "\n",
        "3. Feature Extraction\n",
        "\n",
        "4. Fine-Tuning\n",
        "\n",
        "***\n",
        "\n",
        "**Key Steps in Fine-Tuning**\n",
        "\n",
        "1. Load the Pre-trained Model\n",
        "\n",
        "2. Modify the Output Layer\n",
        "\n",
        "3. Freeze Initial Layers\n",
        "\n",
        "4. Train the Modified Layerrs\n",
        "\n",
        "5. Optional Unfreezing and Fine-Tuning\n",
        "\n",
        "6. Evaluate and Adjusy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_AfOVc-MaDIF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "B64IFK49baB9"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PNdZ6KH5bmVd"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "in_channel = 3\n",
        "num_classes = 10\n",
        "learning_rate = 1e-3\n",
        "batch_size = 1024\n",
        "num_epochs = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FQ4D0n4iZLT"
      },
      "source": [
        "- We use CIFAR10 dataset\n",
        "- So the ouput of model should be number 10\n",
        "- Origin Vgg16 model has avgpool -> AdaptiveAvgPool2d(output_size=(7,7))\n",
        "- But, we get output 1x1x10, so we don't need avgpool\n",
        "- And also, out_features should be 10\n",
        "- We should remove avgpooling and change out_features number to 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## Version 1"
      ],
      "metadata": {
        "id": "0LlpavJ4JSTZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHlK7M1FdgzJ",
        "outputId": "261c650b-7649-4cfc-b3ce-c55ee04e4b3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): Identity()\n",
              "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "#import sys\n",
        "\n",
        "class Identity(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Identity, self).__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x\n",
        "\n",
        "# Load pretrain model & modify it\n",
        "model = torchvision.models.vgg16(pretrained=False)\n",
        "\n",
        "\n",
        "# 1. remove avgpool\n",
        "model.avgpool = Identity()\n",
        "\n",
        "# 2. change out_features to 10 by using just one layer\n",
        "model.classifier = nn.Linear(512, 10) # We can change all classifier by this code / if we code model.classfier[0] = nn.Linear(512, 10) -> we only can change the first one\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "#print(model)\n",
        "#sys.exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Another examples\n",
        "\n",
        "### change classifer\n",
        "\n",
        "model.classifier = nn.Sequential(nn.Linear(512, 100),\n",
        "                                 nn.Dropout(p=0.5),\n",
        "                                 nn.Linear(100, 10))\n",
        "\n",
        "for i in range(1, 7):\n",
        "  model.classifier[i] = Identity()\n",
        "\n",
        "<br>\n",
        "\n",
        "### Freeze all layers, and back prop only last layer\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "3rlxyy_lLkvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "##Version2"
      ],
      "metadata": {
        "id": "lVAP4ntdJWYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import sys\n",
        "\n",
        "class Identity(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Identity, self).__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x\n",
        "\n",
        "# Load pretrain model & modify it\n",
        "model = torchvision.models.vgg16(pretrained=True)\n",
        "\n",
        "\n",
        "# Freeze all layers, and back prop only last layer\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "\n",
        "# 1. remove avgpool\n",
        "model.avgpool = Identity()\n",
        "\n",
        "# 2. change out_features to 10 by using just one layer\n",
        "model.classifier = nn.Sequential(nn.Linear(512, 100),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Linear(100, 10)) # We can change all classifier by this code / if we code model.classfier[0] = nn.Linear(512, 10) -> we only can change the first one\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "#print(model)\n",
        "#sys.exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5j935tJInYT",
        "outputId": "74cabf7e-a3ad-43ff-cc65-6a475e523b9c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): Identity()\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCTveU0Fb1XZ",
        "outputId": "ca13530b-20a5-4cdf-fd58-d08b22a09b07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "train_dataset = datasets.CIFAR10(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "TtpvWc62cFyg"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkjM4yi8cRrU",
        "outputId": "dee850a3-7c65-4e9f-9582-00187bfe057c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost at epoch 0 is 2.3171882969992503\n",
            "Cost at epoch 1 is 2.0880811311760725\n",
            "Cost at epoch 2 is 1.822820680482047\n",
            "Cost at epoch 3 is 1.64486533768323\n",
            "Cost at epoch 4 is 1.484041505930375\n"
          ]
        }
      ],
      "source": [
        "#Train Network\n",
        "for epoch in range(num_epochs):\n",
        "  losses = []\n",
        "\n",
        "  for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "    # Get data to cuda if possible\n",
        "    data = data.to(device=device)\n",
        "    targets = targets.to(device=device)\n",
        "\n",
        "    # forward\n",
        "    scores = model(data)\n",
        "    loss = criterion(scores, targets)\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # gradient descent of adam step\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'Cost at epoch {epoch} is {sum(losses)/len(losses)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model):\n",
        "    if loader.dataset.train:\n",
        "        print(\"Checking accuracy on training data\")\n",
        "    else :\n",
        "        print(\"Checking accuracy on test data\")\n",
        "\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device).squeeze(1)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "        print(f'Got {num_correct} / {num_samples} with accuracy \\\n",
        "              {float(num_correct)/float(num_samples)*100:.2f}')"
      ],
      "metadata": {
        "id": "8yDaSTbbGSbG"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_accuracy(train_loader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYpJwaOfGS-Q",
        "outputId": "ff148f27-05a0-484f-c9ec-9a66590a24e9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking accuracy on training data\n",
            "Got 21919 / 50000 with accuracy               43.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. All layers caculate back prop(pretrained=False)\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAaQAAAAzCAYAAADYWHx6AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAAAWOSURBVHhe7d0NbvM2DIDhbjdp73+mXmUbsbLgR5ASZcmOHL8PYLSWSEp27Cj9zV///OcDAIAX+/vnIwAAL8WCBADYAgsSAGALLEgAgC2wIAEAtsCCBADYAgsSAGAL5QXp6+vrd7P8/moj9c+eC/Z1xWM/O8ZO1+foXLi3cIXSgiQX4/f39+/GxQkAWK27IOliZO26KPl5AivNXl9cn0DbLX+GxFdoAPB+uv/LLvoKydJ+u0hE8SP9QmP8+H7fivq0zdaP8rVfY7MxIra2aNVXPibrj+bi23Tf1vD9lq8nshg/lsraM625yX7W32PzrJExfI1sfK1j9WpbM/nar7HZGBlf39awfcLW9n2qFTM6N+CXLEgtn5+fP5/FpN/HzO4LbbN9UZyV1fHtrf0oviWKbdVXtq3V38sVsh/FiWq+p20jdTOt8eTzVn9VKycaQ0Xto7G+fXW+3Y/ie6J62hbVqraJkVigZ8m37FqviOwrMSX7+qoq6he+LYuraOX5uqNj9OJ7x1c9/p4svlenN758lBgry4lEsb5mtdaMbIwVY8/WaOX78zc6Vnb+1Wg9bzYfsC75GZLcFH4bIfE7X/gzx3aF3ef3ak8/P7PHP5sPqMML0siFJ4tJtFVJ7K4Xuszr6HFdYcX8JEfPv9Z7F7s/fmebPf6nnz+sdZvfspMLXZ8UV/J1zxgDOIrrE0/SXZCihUD2q6+EsoVE23r9VhY7S+vKVj2uqpXHf4bq+Bo3en6i+kfqPJmew5XnH9hR+S3M7UVsb4roJsnarGp/tb6oxtq2kfoZibck19eIYqxWv+8Tvt/Xs6LaPqc1vuqN02Lr+3F9zaPjjIxh2TwhsdV5VdvEkfyR+i2SoyTXj2H5fuVrqGo+0FNekN5ZdEPhf9mTEK7D9YmnYEECAGzhNr/UAAB4byxIAIAtsCABALbAggQA2AILEgBgCyxIAIAtTP9hbNXMH8pV/w4jG+Oq/KpsnIgfW/l8G9c7hjP6V5AxstpZXysHwJ/0Prb3jL23xej9NJIfjf8HWZB6/PubHHm/k6PvkVJ5vxXZ1827In/USH4l1sdcvb9Kq27Wd9ZcgHck94u9Z6L7Z+SeGs2XvlZ/91t20StQ2fer4ivJfFqrcs9s/ojofM7oPT5n96/kxwGwTnQvX6ky/uGfIV11YDxJAcA5dnt+XfZLDbL66WbZtizmKeS4j1wA9rzd7dxl843aszZt189bcVFfj83N8nsxWX8Wa+m+5kb9WZ/KYlrxeA55vF+5+JTH//nWXary/UQfE+VU6lS06lTHzWrM5vccyeuNn9XU9rP7e2xc9rlq1cz6pN33tep4UWylnm1r9fdyhexHcaKa72nbSF28L/t4+8de9u02qpJv27MYMfwVkqx0uum+X/lkX/tXisbq0bnYbcRsvpK80bmLIzlPM3OOernZ46Ztvf6qLL5Xpze+fPTX7NFrEffUe7ylz27+emnR2q38ketteEHSQa82clCezvno3GfzsTe5tuy2m93nB6yy7GdIZ5Kb8M4Lwd3nv4Keg92eUHVedtvJivlJjp53rYdnsI+7brp/hdHxt1+QZOIzN1B24FWz+bNePf4s+2SoZh9TADVyn/lN28XZzy9+bB1XP3rdBUkSoycUlfVnAz7N2eeid/7P7q+y9e4kOn6hbb3+s1XH17i7nX/s44pr+vC/DvIXt++PVGK87CRE+X5OytdozW8mP5LVHFEZ38a8or9Fcm2O31dZu4rmEOX06ni2rpBcXyOKsVr9vk/4fl/Pimr7nNb4qjcOnuHItSOy66ear1rXIW9hDrwx+2TRe6IAXo0FCQCwhVv8lh0A4P2xIAEAtsCCBADYAgsSAGALLEgAgC2wIAEAtsCCBADYAgsSAGALLEgAgA18fPwLUjVRtCVf1IkAAAAASUVORK5CYII=)\n",
        "\n",
        "***\n",
        "\n",
        "2. Version 2\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAaUAAAAtCAYAAAAORnSvAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAAAVFSURBVHhe7d0LcuM2DIDhtDdJ7n+mXKUtpsEWiwIgKEo2Zf/fjGct4kFZlsXESdZ//PWPDwAANvDnz78AADwdixIAYBssSgCAbbQWpa+vr183y2+fbab/1fuCfT3iuV+dY6fzc3ZfeG3hkYaLkpyQ39/fv26coACAq5SLki5I1q4Lk99P4Eyr5xfnJ9Bzu58p8Z0aALyu8u+Uou+ULI3bhSLKn4kLzfHz+20riumY7R/Va1xzszkitreo+iufk8WjffFjum17+Ljl+4ksx8+lsvFMtW+yncVHbJ01M4fvkc2vfaxRb2ulXuOam82R8f1tDxsTtrePqSpndt+A/5FFKfP5+flzLyZxn7O6LXTMxqI8K+vjx6vtKL8S5Vb9lR2r4qNaIdtRnujWezo20zdTzSf3q3hXVRPNoaLx2Vw/fna93Y7yR6J+Ohb16o6JmVyga/ntu+orI/sVmZJt/eoqigs/luV1VHW+7+wco/zR4+s+/pEsf9RnNL/8KzlWVhOJcn3Pbq8V2RxnzL3ao6r3x292ruz4q9l+3mo9ELn8Z0rywvC3GZK/88m/8tgeYff9e7Z3Pz6rj3+1HvAOLUozJ58sKNGtS3J3Pdllv44+rkc4Y/+kRo+/9nsVuz9/V1t9/O9+/HCNW/z2nZzsemE8k+97xRzAUZyfeEflohQtBrLd/YooW0x0bBS3stxV2ldu3cfVdebjv0J3fs2bPT5R/yN93pkewzOPP7Cz1kdX2BPZvjCiF0o2ZnXj3f6im2vHZvpnJN+SWt8jyrGquI8JH/f9rKi3r6nmV6N5Kra/n9f3PDrPzByWrROS292v7pg4Uj/TvyI1Smr9HJaPK99DdeuBrrf/PKXoRYV/ZRciPA7nJ94NH/IHANjGLX7RAQDwHliUAADbYFECAGyDRQkAsA0WJQDANliUAADbWPrj2a6VP6br/p1GNseofjU+K9vPiJ9bVfsY9b46fgaZI+udxaoaAL+/doV/vYziFV+rbI9D/WVRqvjPRznyeSlHP2Ol83ktsq03bzS2Gj9ipr6T63MevX2Wqm8Wu2pfgFcQvT7s2Ch+xBn9y7fvoq9EZTtbIZ9B9qe1+m4gOp4rRs/P1fEz+XkA3Et0vTji0M+UHnUBWZ2HCx0A/MdeE3e9Pp7yiw6yQurNsmNZzruQx33kJLDH7W7HLtvfaDwb03G9X+VFsRFbm9WPcrJ4lmvpttZG8SymspwqHziTnFOnLXI/b+OFOu//+Zyj7yNmpNbeMllsVL8a7zpSG9XYsaynjl8dH7F52X1V9cxiMu5jVR8vyu30s2NVfFQrZDvKE916T8dm+uL1yPPsb5VRvJLV2rm7/acWJd88mySqO0t3zozNi2pm4l1HajKj/RM6fnV8xOZl91XVM4vN9umw9aNeR+J+bNTDs/md2tX5cF/Rc509/6vnRXeuzjxTb9/Jt2e7vg8JHKFveeltN7vvH+5PzquV6/pqvccfz17s7CfsjvQY7HZR1f2yt52csX9So8dd+wFqx3Ni60VJX0xHrdY/2933314Q1Y4vAuAd7fpaLBel7KKiuOjUrj4Wo+N/dbzL9ruT6PELHRvFr9adX/Pudvyxj0ed0+LQfzPkT3Afj3RyIv5gVP2j2Kh+NV7J9mlGZ36b84x4RWptjd9W2biK9iGqGfXxbF8htb5HlGNVcR8TPu77WVFvX1PNr0bz4DVV54aPqdnzZxSzOucgH4cOvCh7QehcDIAdsCgBALbBb98BALbBogQA2AaLEgBgGyxKAIBtsCgBALbBogQA2AaLEgBgEx8ffwPJxM4D8z+ZOQAAAABJRU5ErkJggg==)"
      ],
      "metadata": {
        "id": "D2VHAcqxGphe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Version1 vs Version2\n",
        "> Let's compare v1 and v2\n",
        "\n",
        "<br>\n",
        "\n",
        "***\n",
        "\n",
        "###Version1\n",
        "\n",
        "1. **No pre-trained weights(pretrained=False)**\n",
        "  - model is initialized with random weights\n",
        "  - training starts from the beggining using the CIFAR-10 dataset.\n",
        "\n",
        "2. **Removing the average pooling layer**\n",
        "\n",
        "3. **Simple classifier modification**\n",
        "  - the final layer is replaced with a single linear layer tailored for CIFAR-10\n",
        "\n",
        "\n",
        "***\n",
        "\n",
        "###Version2\n",
        "\n",
        "\n",
        "1. **Using pre-trained weights(pretrained=True)**\n",
        "  - the model is initialized with weights pre-trained on the ImageNet dataset\n",
        "  - starts with well-trained weights, potentially leading to faster convergence\n",
        "\n",
        "\n",
        "2. **Freezing layers**\n",
        "  - keeps the pre-trained weights fixed, training only last layer\n",
        "  - Leverage the knowledge from the pre-training\n",
        "\n",
        "3. **Removing the average pooling layer**\n",
        "\n",
        "4. **Complex classifier modification**\n",
        "  - changes the classifier to a more complex structure with two linear layers and a ReLU activation function\n",
        "  - Allows for more refined training tailored to the CIFAR-10 dataset\n",
        "\n",
        "***\n",
        "\n",
        "###Significance of the Comparison\n",
        "\n",
        "\n",
        "1. **Impact of initial weights**\n",
        "  - in the first method, the model starts training from scratch, which can be slower and may require more data and time\n",
        "  - in the second method, using pre-trained weights can lead to faster training and good performance with less data\n",
        "\n",
        "2. **Generalization capability**\n",
        "  - the first method might overfit to the specific dataset\n",
        "  - the second method, using pre-trained weights, may generalize better as it already learned diverse features\n",
        "\n",
        "3. **Training efficiency**\n",
        "  - the second methond reduces the number of parameters to train by freezing most layers, enchancing efficiency\n",
        "  - the first method trains all parameters, requiring more computational resources\n",
        "\n",
        "4. **Performance comparsion**\n",
        "  - comparing the performance of both method helps evaluate the benefits of using pre-trained weights and freezing layers\n",
        "  - it also assesses the impact of a more complex classifier structure on performance"
      ],
      "metadata": {
        "id": "x4KZE1cuMjyM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EDmQtD50N5BS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNlhvECBOo21e7+TtDnvQHW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}