{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1va_Vv0T0BUR934zAyISHjTMsJP6XHVBq","authorship_tag":"ABX9TyNm5mTqXuEskNozyIt0nw0R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9C1Gh2bz5NGm"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision\n","from torch.utils.data import DataLoader\n","from customDataset import CatAndDogDataset"]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_avilable() else 'cpu')"],"metadata":{"id":"bQrkTBeKCfjH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["in_channel = 3\n","num_classes = 10\n","learning_rate = 1e-3\n","batch_size = 32\n","num_epochs = 1"],"metadata":{"id":"Y1bHRJFnDEeU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Data\n","dataset = CatsAndDogdataset(csv_file = 'cats_dogs.csv', root_dir = 'cats_dogs_resized',\n","                            transform = transforms.ToTensor())\n","train_set, test_set = torch.utils.data.random_split(dataset, [20000, 5000])\n","train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n","train_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"gEn-Z-1HDwnE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model\n","model = torchvision.models.googlenet(pretrained=True)\n","model.to(device)"],"metadata":{"id":"un5QyjCSFsXw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"n5tE660OF19f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train Network\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, targets) in enumerate(train_loader):\n","        # Get data to cuda if possible\n","        data = data.to(device=device).squeeze(1) # Nx1x28x28 -> Nx28x28\n","        targets = targets.to(device=device)\n","\n","        # forward\n","        scores = model(data)\n","        loss = criterion(scores, targets)\n","\n","        # backward\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        # gradient descent or adam step\n","        optimizer.step()"],"metadata":{"id":"k-OHgg4AGGPf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check accuracy on training & test to see how good our model\n","def check_accuracy(loader, model):\n","    if loader.dataset.train:\n","        print(\"Checking accuracy on training data\")\n","    else :\n","        print(\"Checking accuracy on test data\")\n","\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device).squeeze(1)\n","            y = y.to(device=device)\n","\n","            scores = model(x)\n","            _, predictions = scores.max(1)\n","            num_correct += (predictions == y).sum()\n","            num_samples += predictions.size(0)\n","\n","        print(f'Got {num_correct} / {num_samples} with accuracy \\\n","              {float(num_correct)/float(num_samples)*100:.2f}')\n","\n","    model.train()"],"metadata":{"id":"vTsUyJ9yHmIB"},"execution_count":null,"outputs":[]}]}